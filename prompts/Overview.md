# Overview

Prompt "engineering" helps you get better outputs. Basically how do you sweet talk the machine to give you the most optimized response.

### Models

[alt text](image.png)

### Best Practices

- Clear Instructions
- Give it a persona (You are an English teacher...)
- Specificy the format
- Limit Scope (100 words / code blocks)

### Technical
- LLMS interpret our prompts as text vectors (i.e food is [0.01, 0.02 ...]) and mashes that computation up. Check OpenAI Embeddings in their docs. 

### Interesting

- AI Hallucination = LLM generates false information

### Resources

- [Prompt Engineering Tutorial â€“ Master ChatGPT and LLM Responses](https://www.youtube.com/watch?v=_ZvnD73m40o)
